1.
	The SVM gets ~6.9% loss, while the least squares method gets ~6.5% loss. One explanation might be that the SVM, being able to pick up on more complex patterns,  picked up on a pattern in the training set causing it to overfit. 

2. 
	My error rate was 2% on this question, however my computing power is fairly limited. 
	As sigma approaches 0 we see that the error reaches 100% because the gaussian becomes sharper and similarities need to become more exact (see example on paper). As the sigma approaches infinity we notice that the error reaches 50% because the gaussian becomes fatter and therefore cannot differentiate between 7's and 9's.
	
construct a gasussian with some parameters
sample w1..wk points from gaussian with some pararmter
construct feature map
map data to fature map
do linear regression to that map

Use best sigma from 2 in problem 3

spline is basically a polynomial kernel?
check wikipedia

X is k * n matrix
W is D * k matrix
Z is D by n 
